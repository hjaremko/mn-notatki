\documentclass[../mn-notatki.tex]{subfiles}

\begin{document}

\section{Układy równań liniowych}

\begin{tcolorbox}
\[
Ax = b
\]
\[
\text{gdzie } A \in \mathbb{R}^{n \times n}, b \in \mathbb{R}^n
\]
\end{tcolorbox}

\subsection{Rozkład LU}

\begin{tcolorbox}
\[
A = LU
\]
\[
Ax = L(Ux) = b
\]
\[
\begin{cases}
Lz = b\\
Ux = z
\end{cases}
\]
\end{tcolorbox}

\subsubsection{Metoda Doolittle'a}
\subsubsection{Metoda Crouta}
\subsubsection{Metoda Cholesky'ego}

\begin{tcolorbox}
Jeśli macierz $A$ jest \textbf{symetryczna i dodatnio określona} to istnieje
macierz dolnotrójkątna $L$ taka, że $L\cdot L^T = A$.\\
Ten rozkład nazywamy rozkładem Cholesky'ego.\\

\textbf{NIE SPRAWDZAMY} czy macierz jest dodatnio określona. Wykonujemy
algorytm i sprawdzamy czy pod pierwiastiem nie otrzymamy liczby ujemnej.\\
\textbf{Należy} sprawdzić czy macierz jest symetryczna.
\end{tcolorbox}
\begin{gather*}
l_{11} = \sqrt{a_{11}}\\
l_{j1} = \frac{a_{j1}}{l_{11}}\\
l_{ii} = \sqrt{a_{ii} - \sum_{k=1}^{i-1} l_{ik}^2}, \text{~~ dla ~~} j = 2, 3, \ldots, n\\
l_{ji} = \frac{1}{l_{ii}} \left( a_{ji} - \sum_{k=1}^{i-1} l_{jk} l_{ik} \right),
\text{~~ dla ~~}
\begin{cases}
i = 2,3 \ldots, n\\
j = i +1, i+2, \ldots, n
\end{cases}
\end{gather*}

\subsubsection{Istnienie rozkładu LU}

\begin{tcolorbox}
Jeśli $A = [a_{ij}]$ jest macierzą kwadratową $n\times n$ taką, że wszystkie
minory główne są nieosobliwe, tzn.:
\[
\begin{vmatrix}
a_{11} & \ldots & a_{1k}\\
\vdots & \ddots & \vdots\\
a_{k1} & \ldots & a_{kk}
\end{vmatrix} \neq 0, \text{~~~~~dla~~~} 1,\ldots,n
\]
to istnieją rozkłady $A = LU$ Crouta i Doolittle'a.
\end{tcolorbox}
\begin{tcolorbox}
Jeśli macierz $A \in \mathbb{R}^{n\times n}$ jest nieosobliwa to istnieją
rozkłady $PA = LU$ Crouta i Doolittle'a, gdzie $P$ jest macierzą permutacji.
\end{tcolorbox}

\subsection{Algorytm eliminacji Gaussa}

Oznaczamy przez $A_i$ $i$-ty wiersz macierzy $A$ \textit{(jako wektor)}.
Wtedy $k$-ty krok algorytmu Gaussa możemy podzielić na następujące etapy:
\begin{itemize}
    \item W podmacierzy $A(k\ldots n, k\ldots n)$ wybierz element głowny $x_k$.
    \item Zamień wiersze lub kolumny tak, aby element głowny $x_k$ znalazł się
    na pozycji $a_kk$.
    \item Wyzeruj elementy pod elementem głownym.
    \[
    A_i \leftarrow A_i - \frac{a_{ik}}{a_{kk}} \cdot A_k, \text{~~ dla ~~} k+1, \ldots, n
    \]
\end{itemize}

\subsubsection{Wybór elementu głównego}

\begin{tcolorbox}
\textbf{Częściowy} - wybieramy największy na moduł element w pierwszej kolumnie
bieżącej podmacierzy.
\end{tcolorbox}

\begin{tcolorbox}
\textbf{Pełny} - wybieramy największy na moduł element w całej
bieżącej podmacierzy.
\end{tcolorbox}

\begin{tcolorbox}
\textbf{Skalowany} - na poczaku całego algorytmu dla każdego wiersza obliczamy
jego normę $s_i$ \textit{(najczęściej maksimum)}, w $k$-tym kroku wybieramy
element $a_{ik}$ z pierwszej kolumny podmacierzy, którego
$\frac{|a_{ik}|}{s_i}$ jest największe.
\end{tcolorbox}

\subsection{Odwracanie macierzy trójkątnych}
\subsection{Odwracanie przez rozkład LU}

\begin{tcolorbox}
Jeśli mamy rozkład $A = LU$ to macierz odwrotną do $A$ możemy wyznaczyć przez
\begin{itemize}
    \item $A^{-1} = U^{-1} \cdot L^{-1}$
\end{itemize}
Powyższy algorytm wykorzystuje fakt, że
\[
(D\cdot G)^{-1} = G^{-1} \cdot D^{-1}
\]
\end{tcolorbox}

Usprawniamy algorytm rozwiązując równania
\[
Ax_i = LUx_i = e_i
\]
gdzie $e_i$ to kolejne wektory jednostkowe. Wektory $x_i$ są kolejnymi
kolumnamy macierzy $A^{-1}$.

\subsection{Poprawianie iteracyjne}

\begin{itemize}
    \item $x_0$ - przybliżenie początkowe
    \item $A = LU$ - macierz
    \item $\varepsilon$ - zakładana precyzja
\end{itemize}
\begin{tcolorbox}
\textbf{Algorytm - jeden krok}
\begin{itemize}
    \item $r_k = b - Ax_k$
    \item jeżeli $|r_k| < \varepsilon$ zakończ i zwróć $x_k$
    \item $e_k = $ rozwiązanie układu $Ae_k = LUe_k = r_k$
    \item $x_{k+1} = x_k + e_k$
\end{itemize}
\end{tcolorbox}

\begin{itemize}
    \item Wektor rezydualny $r_k$ należy obliczyć w wyższej precyzji
    \textit{(np. \texttt{double} dla \texttt{float}, \texttt{long double} dla
    \texttt{double})} bo mamy tam znaczne kasowanie bitów znaczących.
    \item Jeżeli obliczając $x_0$ dokonaliśmy rozkładu $LU$ macierzy $A$ to
    jeden krok poprawiania jest tani \textit{(koszt kwadratowy)}.
\end{itemize}


\pagebreak
\end{document}
